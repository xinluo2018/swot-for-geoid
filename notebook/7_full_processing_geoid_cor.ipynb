{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f913504",
   "metadata": {},
   "source": [
    "### full processing for:\n",
    "(1) the quantification of spatial variation of lake surface height;   \n",
    "(2) the correction of orthometric height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aee5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "import geopandas as gpd\n",
    "from utils.functions import meter2deg\n",
    "from utils.pixc2raster import pixc2raster\n",
    "from utils.functions import pixc_geophy_cor\n",
    "from utils.functions import sample_from_raster \n",
    "from utils.swot_data_mask import swot_pixc_mask\n",
    "from utils.swot_data_filter import iter_IQR, pixc_height_local_filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff326e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "lake_name = 'dianchi'\n",
    "dir_pixc = f'data/{lake_name}-lake/swot-pixc'\n",
    "path_lake_vec = f'data/{lake_name}-lake/hydrolake_{lake_name}_edit.gpkg'\n",
    "## Check original .nc file.\n",
    "paths_pixc = [p for p in glob(dir_pixc + '/SWOT*.nc') if '_masked' not in p and 'filter' not in p and 'height' not in p]\n",
    "paths_pixc = sorted(paths_pixc)\n",
    "print(len(paths_pixc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caedd9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hylak_id</th>\n",
       "      <th>Lake_name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Poly_src</th>\n",
       "      <th>Lake_type</th>\n",
       "      <th>Grand_id</th>\n",
       "      <th>Lake_area</th>\n",
       "      <th>Shore_len</th>\n",
       "      <th>Shore_dev</th>\n",
       "      <th>...</th>\n",
       "      <th>Vol_src</th>\n",
       "      <th>Depth_avg</th>\n",
       "      <th>Dis_avg</th>\n",
       "      <th>Res_time</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Slope_100</th>\n",
       "      <th>Wshd_area</th>\n",
       "      <th>Pour_long</th>\n",
       "      <th>Pour_lat</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1483</td>\n",
       "      <td>Dian Chi</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>SWBD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>298.34</td>\n",
       "      <td>141.84</td>\n",
       "      <td>2.32</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>19.7</td>\n",
       "      <td>44.051</td>\n",
       "      <td>1540.3</td>\n",
       "      <td>1886</td>\n",
       "      <td>2.71</td>\n",
       "      <td>2875.6</td>\n",
       "      <td>102.603578</td>\n",
       "      <td>24.782792</td>\n",
       "      <td>MULTIPOLYGON (((102.64217 24.9598, 102.64891 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hylak_id Lake_name Country Continent Poly_src  Lake_type  Grand_id  \\\n",
       "0      1483  Dian Chi   China      Asia     SWBD          1         0   \n",
       "\n",
       "   Lake_area  Shore_len  Shore_dev  ...  Vol_src  Depth_avg  Dis_avg  \\\n",
       "0     298.34     141.84       2.32  ...        3       19.7   44.051   \n",
       "\n",
       "   Res_time  Elevation  Slope_100  Wshd_area   Pour_long   Pour_lat  \\\n",
       "0    1540.3       1886       2.71     2875.6  102.603578  24.782792   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((102.64217 24.9598, 102.64891 2...  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read vector file of the lake.\n",
    "lake_gdf = gpd.read_file(path_lake_vec)\n",
    "lake_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf16a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_decrease_gdf = lake_gdf.copy()\n",
    "lon_center = lake_decrease_gdf.bounds.mean(axis=1).values\n",
    "utm_zone = np.floor(lon_center/6)+31\n",
    "epsg_code = f'326{int(utm_zone[0])}'\n",
    "lake_decrease_gdf = lake_decrease_gdf.to_crs(epsg=epsg_code)\n",
    "lake_decrease_gdf['geometry'] = lake_decrease_gdf.geometry.buffer(-200)  # interior buffer\n",
    "lake_decrease_gdf = lake_decrease_gdf.to_crs(epsg=4326)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e9af79",
   "metadata": {},
   "source": [
    "### data mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23235e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input file: 0 data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_009_049_198L_20240105T211648_20240105T211659_PIC0_01.nc\n",
      "file written to data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_009_049_198L_20240105T211648_20240105T211659_PIC0_01_masked.nc\n",
      "input file: 1 data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_010_049_198L_20240126T180154_20240126T180205_PIC0_01.nc\n",
      "file written to data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_010_049_198L_20240126T180154_20240126T180205_PIC0_01_masked.nc\n",
      "input file: 2 data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_012_049_198L_20240308T113203_20240308T113214_PIC0_01.nc\n",
      "file written to data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_012_049_198L_20240308T113203_20240308T113214_PIC0_01_masked.nc\n",
      "input file: 3 data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_014_049_198L_20240419T050213_20240419T050224_PIC0_01.nc\n",
      "file written to data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_014_049_198L_20240419T050213_20240419T050224_PIC0_01_masked.nc\n",
      "input file: 4 data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_016_049_198L_20240530T223221_20240530T223232_PIC0_01.nc\n",
      "file written to data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_016_049_198L_20240530T223221_20240530T223232_PIC0_01_masked.nc\n",
      "input file: 5 data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_018_049_198L_20240711T160229_20240711T160240_PIC0_01.nc\n",
      "file written to data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_018_049_198L_20240711T160229_20240711T160240_PIC0_01_masked.nc\n",
      "input file: 6 data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_019_049_198L_20240801T124734_20240801T124745_PIC0_02.nc\n",
      "file written to data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_019_049_198L_20240801T124734_20240801T124745_PIC0_02_masked.nc\n",
      "input file: 7 data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_021_049_198L_20240912T061744_20240912T061755_PIC0_01.nc\n",
      "file written to data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_021_049_198L_20240912T061744_20240912T061755_PIC0_01_masked.nc\n",
      "input file: 8 data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_025_049_198L_20241204T171804_20241204T171816_PIC2_01.nc\n",
      "file written to data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_025_049_198L_20241204T171804_20241204T171816_PIC2_01_masked.nc\n"
     ]
    }
   ],
   "source": [
    "pixcs_masked = []\n",
    "for i, path in enumerate(paths_pixc):\n",
    "  print(f'input file: {i} {path}')\n",
    "  # Define the output path\n",
    "  path_masked = path.split('.')[0]+'_masked.nc'\n",
    "  pixc_nc = xr.open_dataset(path, group='pixel_cloud')\n",
    "  pixc_masked = swot_pixc_mask(pixc_nc=pixc_nc, \n",
    "                                vars_sel=['latitude', 'longitude', 'height', \n",
    "                                          'solid_earth_tide', 'pole_tide', \n",
    "                                          'load_tide_fes', 'iono_cor_gim_ka', 'geoid',\n",
    "                                          ],\n",
    "                                region_gdf=lake_decrease_gdf, \n",
    "                                path_masked=path_masked)\n",
    "  pixcs_masked.append(pixc_masked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269c634b",
   "metadata": {},
   "source": [
    "### data filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8ee157f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_009_049_198L_20240105T211648_20240105T211659_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_010_049_198L_20240126T180154_20240126T180205_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_012_049_198L_20240308T113203_20240308T113214_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_014_049_198L_20240419T050213_20240419T050224_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_016_049_198L_20240530T223221_20240530T223232_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_018_049_198L_20240711T160229_20240711T160240_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_019_049_198L_20240801T124734_20240801T124745_PIC0_02_masked_filtered.nc\n",
      "Filtered data saved to: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_021_049_198L_20240912T061744_20240912T061755_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_025_049_198L_20241204T171804_20241204T171816_PIC2_01_masked_filtered.nc\n"
     ]
    }
   ],
   "source": [
    "pixcs_filtered_ds = []\n",
    "for i, pixc_masked in enumerate(pixcs_masked):\n",
    "    pixc_ht_filter_ds = pixc_masked[['geoid', 'height']]\n",
    "    ## 1. geophysical correction for height, and convert to orthometric height\n",
    "    pixc_ht_cor = pixc_geophy_cor(pixc_nc=pixc_masked)\n",
    "    pixc_ht_ortho = pixc_ht_cor - pixc_masked.geoid.values\n",
    "    pixc_ht_filter_ds = pixc_ht_filter_ds.assign({'ht_ortho': ((\"points\",), pixc_ht_ortho)})\n",
    "    pixc_ht_filter_ds.ht_ortho.attrs['description'] = 'PIXC height data with geophysical correction and orthometric correction (use geoid variable)'\n",
    "\n",
    "    ## 2. height filtering \n",
    "    ## 2.1 height filtering in global region using IQR method\n",
    "    pixc_ht_ortho_filter1, IQR = iter_IQR(pixc_ht_ortho, IQR_thre=0.3, iter_max=5)\n",
    "    pixc_ht_ortho_filter1 = pixc_ht_ortho_filter1.filled(np.nan)\n",
    "    pixc_ht_filter_ds = pixc_ht_filter_ds.assign({'ht_ortho_filter1': ((\"points\",), pixc_ht_ortho_filter1)})\n",
    "    pixc_ht_filter_ds.ht_ortho_filter1.attrs['description'] = 'PIXC height data with global filtering using IQR method'\n",
    "    ## 2.2 height filtering in local region\n",
    "    pixc_ht_ortho_filter2 = pixc_height_local_filtering(pixc_height=pixc_ht_ortho_filter1, \n",
    "                                              pixc_lonlat=(pixc_ht_filter_ds.longitude.values, pixc_ht_filter_ds.latitude.values), \n",
    "                                              thre=0.2, \n",
    "                                              radius_m=500)\n",
    "    pixc_ht_filter_ds = pixc_ht_filter_ds.assign({'ht_ortho_filter2': ((\"points\",), pixc_ht_ortho_filter2)})\n",
    "    pixc_ht_filter_ds.ht_ortho_filter2.attrs['description'] = 'PIXC height with both global and local filtering'\n",
    "    pixc_ht_filter_ds = pixc_ht_filter_ds.assign({'ht_valid_ids': ((\"points\",), ~np.isnan(pixc_ht_ortho_filter2))})\n",
    "    pixc_ht_filter_ds.ht_valid_ids.attrs['description'] = 'PIXC height indices of valid data'\n",
    "    pixcs_filtered_ds.append(pixc_ht_filter_ds)\n",
    "\n",
    "    # # 3. save the filtered data\n",
    "    path_pixc_filtered = paths_pixc[i].split('.')[0]+'_masked_filtered.nc'\n",
    "    pixc_ht_filter_ds.to_netcdf(path_pixc_filtered, mode='w', format='NETCDF4')  ## save the filtered data\n",
    "    print(f'Filtered data saved to: {path_pixc_filtered}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e4cd4",
   "metadata": {},
   "source": [
    "### calculate the height variation of lake surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f4a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved to: data/dianchi-lake/swot-pixc/raster_height_spavar.nc\n"
     ]
    }
   ],
   "source": [
    "## calculate the height heterogeneity\n",
    "xmin, ymin, xmax, ymax = lake_gdf.geometry[0].buffer(0.01).bounds\n",
    "raster_extent = (xmin, xmax, ymin, ymax)\n",
    "lat_center = pixcs_filtered_ds[0]['geoid'].latitude.mean().values\n",
    "res_lon, res_lat = meter2deg(meter=500, lat=lat_center)\n",
    "\n",
    "## 1. calculate the spatial variation of ellipsoidal height\n",
    "pixcs_spavar_ls = []\n",
    "for pixc_filtered_ds in pixcs_filtered_ds:\n",
    "    pixc_spavar_xr = pixc_filtered_ds[['geoid', 'ht_valid_ids']]\n",
    "    ## calculate corrected geoid\n",
    "    pixc_ht_ellip = pixc_filtered_ds['ht_ortho_filter2'].values + pixc_filtered_ds['geoid'].values\n",
    "    pixc_ht_ellip_spavar = pixc_ht_ellip - np.nanmean(pixc_ht_ellip) ## i.e., spatial variance of height anomalies\n",
    "    geoid_mean = np.nanmean(pixc_filtered_ds['geoid'])\n",
    "    pixc_geoid_cor = geoid_mean + pixc_ht_ellip_spavar    ## Pixc Geoid correction\n",
    "\n",
    "    ## save as DataArray\n",
    "    pixc_spavar_xr = pixc_spavar_xr.assign({'geoid_cor': ((\"points\",), pixc_geoid_cor)})\n",
    "    pixc_spavar_xr = pixc_spavar_xr.assign({'ht_ellip_spavar': ((\"points\",), pixc_ht_ellip_spavar)})\n",
    "    pixc_spavar_xr['geoid_cor'].attrs['description'] = 'corrected geoid of PIXC points'\n",
    "    pixc_spavar_xr['ht_ellip_spavar'].attrs['description'] = 'spatial variation of lake surface height'\n",
    "    pixcs_spavar_ls.append(pixc_spavar_xr)\n",
    "\n",
    "pixcs_spavar_xr = xr.concat(pixcs_spavar_ls, dim='points')   ## merge multitemporal xarray dataset.\n",
    "pixcs_spavar_xr = pixcs_spavar_xr[['ht_ellip_spavar']]\n",
    "raster_ht_ellip_spavar = pixc2raster(pixc_var = pixcs_spavar_xr['ht_ellip_spavar'], \n",
    "                            raster_extent=raster_extent,\n",
    "                            pixc_lonlat=(pixcs_spavar_xr.longitude.values, \n",
    "                                         pixcs_spavar_xr.latitude.values), \n",
    "                            resolution=(res_lon, res_lat), agg_method='median')\n",
    "raster_ht_ellip_spavar.name = \"height_spavar_smoothed\"\n",
    "## normalization\n",
    "raster_ht_ellip_spavar.values =  raster_ht_ellip_spavar.values - np.nanmean(raster_ht_ellip_spavar.values)\n",
    "## save to path\n",
    "raster_ht_ellip_spavar.attrs['description'] = 'the swot data-derived spatial variation of ellipsoidal height of the lake'\n",
    "raster_height_spavar_ds = xr.Dataset({\n",
    "        'ht_spavar_smoothed': raster_ht_ellip_spavar.rename('ht_spavar_smoothed')\n",
    "        })\n",
    "## Save as NetCDF file\n",
    "path_raster_height_spavar = dir_pixc + '/raster_height_spavar.nc'\n",
    "raster_height_spavar_ds.to_netcdf(path_raster_height_spavar)\n",
    "print(f'data saved to: {path_raster_height_spavar}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55817d93",
   "metadata": {},
   "source": [
    "### calculate pixc-based height_ortho and corrected height_ortho "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a2af856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to save: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_009_049_198L_20240105T211648_20240105T211659_PIC0_01_height.nc\n",
      "Path to save: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_010_049_198L_20240126T180154_20240126T180205_PIC0_01_height.nc\n",
      "Path to save: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_012_049_198L_20240308T113203_20240308T113214_PIC0_01_height.nc\n",
      "Path to save: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_014_049_198L_20240419T050213_20240419T050224_PIC0_01_height.nc\n",
      "Path to save: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_016_049_198L_20240530T223221_20240530T223232_PIC0_01_height.nc\n",
      "Path to save: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_018_049_198L_20240711T160229_20240711T160240_PIC0_01_height.nc\n",
      "Path to save: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_019_049_198L_20240801T124734_20240801T124745_PIC0_02_height.nc\n",
      "Path to save: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_021_049_198L_20240912T061744_20240912T061755_PIC0_01_height.nc\n",
      "Path to save: data/dianchi-lake/swot-pixc/SWOT_L2_HR_PIXC_025_049_198L_20241204T171804_20241204T171816_PIC2_01_height.nc\n"
     ]
    }
   ],
   "source": [
    "for i, pixc_filtered in enumerate(pixcs_filtered_ds):\n",
    "    pixc_ht_ds = pixc_filtered[['geoid', 'ht_ortho_filter2']]\n",
    "    ## 1. extract the pixc corrected geoid from the raster data \n",
    "    pixc_ht_spavar = sample_from_raster(\n",
    "        raster_value = raster_height_spavar_ds.ht_spavar_smoothed.values,\n",
    "        raster_x = raster_height_spavar_ds.x.values,\n",
    "        raster_y = raster_height_spavar_ds.y.values,\n",
    "        points_x = pixc_filtered.longitude.values,\n",
    "        points_y = pixc_filtered.latitude.values\n",
    "    )\n",
    "    pixc_ht_ds = pixc_ht_ds.assign({'ht_spavar': ((\"points\",), pixc_ht_spavar)})\n",
    "    pixc_ht_ds['ht_spavar'].attrs['description'] = 'spatial variation of lake height'\n",
    "    ## 2. calculate pixc height with corrected geoid\n",
    "    geoid_cor = pixc_filtered.geoid.mean(dim='points').values + pixc_ht_ds['ht_spavar'].values\n",
    "    pixc_ht_ortho_cor = pixc_filtered.height.values - geoid_cor\n",
    "    pixc_ht_ortho_cor[~pixc_filtered['ht_valid_ids'].values] = np.nan   ## mask invalid values\n",
    "    pixc_ht_ds = pixc_ht_ds.assign({'ht_ortho_cor': ((\"points\",), pixc_ht_ortho_cor)})\n",
    "    pixc_ht_ds['ht_ortho_cor'].attrs['description'] = 'orthometric height using corrected geoid height'\n",
    "    pixc_ht_ds = pixc_ht_ds.rename({'ht_ortho_filter2': 'ht_ortho'})\n",
    "    pixc_ht_ds['ht_ortho'].attrs['description'] = 'orthometric height (after filtering) using geoid height'\n",
    "    ### 3. save the pixc heights to a new NetCDF file\n",
    "    path_pixc_height = paths_pixc[i].replace('.nc', '_height.nc')\n",
    "    pixc_ht_ds.to_netcdf(path_pixc_height)\n",
    "    print(f\"Path to save: {path_pixc_height}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42377771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df44018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6ac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
