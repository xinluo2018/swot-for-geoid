{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "import geopandas as gpd\n",
    "from utils.functions import sample_from_raster \n",
    "from utils.functions import meter2deg\n",
    "from utils.functions import pixc_geophy_cor\n",
    "from utils.pixc2raster import pixc2raster\n",
    "from utils.swot_data_mask import swot_pixc_mask\n",
    "from utils.swot_data_filter import iter_IQR, pixc_height_local_filtering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bff326e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "lake_name = 'siling_co'\n",
    "dir_pixc = f'data/{lake_name}-lake/swot-pixc'\n",
    "path_lake_vec = f'data/{lake_name}-lake/hydrolake_{lake_name}.gpkg'\n",
    "## Check original .nc file.\n",
    "paths_pixc = [p for p in glob(dir_pixc + '/SWOT*.nc') if '_masked' not in p and 'filter' not in p and 'height' not in p]\n",
    "paths_pixc = sorted(paths_pixc)\n",
    "print(len(paths_pixc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "caedd9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hylak_id</th>\n",
       "      <th>Lake_name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Poly_src</th>\n",
       "      <th>Lake_type</th>\n",
       "      <th>Grand_id</th>\n",
       "      <th>Lake_area</th>\n",
       "      <th>Shore_len</th>\n",
       "      <th>Shore_dev</th>\n",
       "      <th>...</th>\n",
       "      <th>Vol_src</th>\n",
       "      <th>Depth_avg</th>\n",
       "      <th>Dis_avg</th>\n",
       "      <th>Res_time</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Slope_100</th>\n",
       "      <th>Wshd_area</th>\n",
       "      <th>Pour_long</th>\n",
       "      <th>Pour_lat</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>Siling</td>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>SWBD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1749.53</td>\n",
       "      <td>402.54</td>\n",
       "      <td>2.71</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4539</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>29077.1</td>\n",
       "      <td>89.047917</td>\n",
       "      <td>31.777083</td>\n",
       "      <td>MULTIPOLYGON (((88.97853 32.01195, 88.9806 32....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hylak_id Lake_name Country Continent Poly_src  Lake_type  Grand_id  \\\n",
       "0       147    Siling   China      Asia     SWBD          1         0   \n",
       "\n",
       "   Lake_area  Shore_len  Shore_dev  ...  Vol_src  Depth_avg  Dis_avg  \\\n",
       "0    1749.53     402.54       2.71  ...        1       28.0      0.0   \n",
       "\n",
       "   Res_time  Elevation  Slope_100  Wshd_area  Pour_long   Pour_lat  \\\n",
       "0      -1.0       4539       -1.0    29077.1  89.047917  31.777083   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((88.97853 32.01195, 88.9806 32....  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read vector file of the lake.\n",
    "lake_gdf = gpd.read_file(path_lake_vec)\n",
    "lake_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cf16a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_decrease_gdf = lake_gdf.copy()\n",
    "lon_center = lake_decrease_gdf.bounds.mean(axis=1).values\n",
    "utm_zone = np.floor(lon_center/6)+31\n",
    "epsg_code = f'326{int(utm_zone[0])}'\n",
    "lake_decrease_gdf = lake_decrease_gdf.to_crs(epsg=epsg_code)\n",
    "lake_decrease_gdf['geometry'] = lake_decrease_gdf.geometry.buffer(-200)  # interior buffer\n",
    "lake_decrease_gdf = lake_decrease_gdf.to_crs(epsg=4326)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e9af79",
   "metadata": {},
   "source": [
    "### data mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23235e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input file: 0 data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_015_217_210L_20240516T015222_20240516T015234_PIC0_01.nc\n",
      "file written to data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_015_217_210L_20240516T015222_20240516T015234_PIC0_01_masked.nc\n",
      "input file: 1 data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_016_217_210L_20240605T223729_20240605T223740_PIC0_01.nc\n",
      "file written to data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_016_217_210L_20240605T223729_20240605T223740_PIC0_01_masked.nc\n",
      "input file: 2 data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_017_217_210L_20240626T192231_20240626T192243_PIC0_01.nc\n",
      "file written to data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_017_217_210L_20240626T192231_20240626T192243_PIC0_01_masked.nc\n",
      "input file: 3 data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_018_217_210L_20240717T160736_20240717T160747_PIC0_01.nc\n",
      "file written to data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_018_217_210L_20240717T160736_20240717T160747_PIC0_01_masked.nc\n",
      "input file: 4 data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_019_217_210L_20240807T125240_20240807T125252_PIC0_01.nc\n",
      "file written to data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_019_217_210L_20240807T125240_20240807T125252_PIC0_01_masked.nc\n",
      "input file: 5 data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_020_217_210L_20240828T093745_20240828T093756_PIC0_01.nc\n",
      "file written to data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_020_217_210L_20240828T093745_20240828T093756_PIC0_01_masked.nc\n",
      "input file: 6 data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_021_217_210L_20240918T062251_20240918T062302_PIC0_01.nc\n",
      "file written to data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_021_217_210L_20240918T062251_20240918T062302_PIC0_01_masked.nc\n",
      "input file: 7 data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_022_217_210L_20241009T030758_20241009T030809_PIC0_01.nc\n",
      "file written to data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_022_217_210L_20241009T030758_20241009T030809_PIC0_01_masked.nc\n"
     ]
    }
   ],
   "source": [
    "pixcs_masked = []\n",
    "for i, path in enumerate(paths_pixc):\n",
    "  print(f'input file: {i} {path}')\n",
    "  # Define the output path\n",
    "  path_masked = path.split('.')[0]+'_masked.nc'\n",
    "  pixc_nc = xr.open_dataset(path, group='pixel_cloud')\n",
    "  pixc_masked = swot_pixc_mask(pixc_nc=pixc_nc, \n",
    "                                vars_sel=['latitude', 'longitude', 'height', \n",
    "                                          'solid_earth_tide', 'pole_tide', \n",
    "                                          'load_tide_fes', 'iono_cor_gim_ka', 'geoid',\n",
    "                                          ],\n",
    "                                region_gdf=lake_decrease_gdf, \n",
    "                                path_masked=path_masked)\n",
    "  pixcs_masked.append(pixc_masked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269c634b",
   "metadata": {},
   "source": [
    "### data filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8ee157f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_015_217_210L_20240516T015222_20240516T015234_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_016_217_210L_20240605T223729_20240605T223740_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_017_217_210L_20240626T192231_20240626T192243_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_018_217_210L_20240717T160736_20240717T160747_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_019_217_210L_20240807T125240_20240807T125252_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_020_217_210L_20240828T093745_20240828T093756_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_021_217_210L_20240918T062251_20240918T062302_PIC0_01_masked_filtered.nc\n",
      "Filtered data saved to: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_022_217_210L_20241009T030758_20241009T030809_PIC0_01_masked_filtered.nc\n"
     ]
    }
   ],
   "source": [
    "pixcs_filtered_ds = []\n",
    "for i, pixc_masked in enumerate(pixcs_masked):\n",
    "    pixc_ht_filter_ds = pixc_masked[['geoid', 'height']]\n",
    "    ## 1. geophysical correction for height, and convert to orthometric height\n",
    "    pixc_ht_cor = pixc_geophy_cor(pixc_nc=pixc_masked)\n",
    "    pixc_ht_ortho = pixc_ht_cor - pixc_masked.geoid.values\n",
    "    pixc_ht_filter_ds = pixc_ht_filter_ds.assign({'ht_ortho': ((\"points\",), pixc_ht_ortho)})\n",
    "    pixc_ht_filter_ds.ht_ortho.attrs['description'] = 'PIXC height data with geophysical correction and orthometric correction (use geoid variable)'\n",
    "\n",
    "    ## 2. height filtering \n",
    "    ## 2.1 height filtering in global region using IQR method\n",
    "    pixc_ht_ortho_filter1, IQR = iter_IQR(pixc_ht_ortho, IQR_thre=0.3, iter_max=5)\n",
    "    pixc_ht_ortho_filter1 = pixc_ht_ortho_filter1.filled(np.nan)\n",
    "    pixc_ht_filter_ds = pixc_ht_filter_ds.assign({'ht_ortho_filter1': ((\"points\",), pixc_ht_ortho_filter1)})\n",
    "    pixc_ht_filter_ds.ht_ortho_filter1.attrs['description'] = 'PIXC height data with global filtering using IQR method'\n",
    "    ## 2.2 height filtering in local region\n",
    "    pixc_ht_ortho_filter2 = pixc_height_local_filtering(pixc_height=pixc_ht_ortho_filter1, \n",
    "                                              pixc_lonlat=(pixc_ht_filter_ds.longitude.values, pixc_ht_filter_ds.latitude.values), \n",
    "                                              thre=0.2, \n",
    "                                              radius_m=500)\n",
    "    pixc_ht_filter_ds = pixc_ht_filter_ds.assign({'ht_ortho_filter2': ((\"points\",), pixc_ht_ortho_filter2)})\n",
    "    pixc_ht_filter_ds.ht_ortho_filter2.attrs['description'] = 'PIXC height with both global and local filtering'\n",
    "    pixc_ht_filter_ds = pixc_ht_filter_ds.assign({'ht_valid_ids': ((\"points\",), ~np.isnan(pixc_ht_ortho_filter2))})\n",
    "    pixc_ht_filter_ds.ht_valid_ids.attrs['description'] = 'PIXC height indices of valid data'\n",
    "    pixcs_filtered_ds.append(pixc_ht_filter_ds)\n",
    "\n",
    "    # # 3. save the filtered data\n",
    "    path_pixc_filtered = paths_pixc[i].split('.')[0]+'_masked_filtered.nc'\n",
    "    pixc_ht_filter_ds.to_netcdf(path_pixc_filtered, mode='w', format='NETCDF4')  ## save the filtered data\n",
    "    print(f'Filtered data saved to: {path_pixc_filtered}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e4cd4",
   "metadata": {},
   "source": [
    "### calculate the height heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32f4a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved to: data/siling_co-lake/swot-pixc/raster_height_spahet.nc\n"
     ]
    }
   ],
   "source": [
    "## calculate the height heterogeneity\n",
    "xmin, ymin, xmax, ymax = lake_gdf.geometry[0].buffer(0.01).bounds\n",
    "raster_extent = (xmin, xmax, ymin, ymax)\n",
    "lat_center = pixcs_filtered_ds[0]['geoid'].latitude.mean().values\n",
    "res_lon, res_lat = meter2deg(meter=500, lat=lat_center)\n",
    "\n",
    "## 1. calculate the spatial heterogeneity of height anomalies\n",
    "rasters_ht_spahet = []\n",
    "\n",
    "for pixc_filtered_ds in pixcs_filtered_ds:\n",
    "    pixc_geoid_cor_ds = pixc_filtered_ds[['geoid', 'ht_valid_ids']]\n",
    "    ## calculate corrected geoid\n",
    "    pixc_ht_ellip = pixc_filtered_ds['ht_ortho_filter2'].values + pixc_filtered_ds['geoid'].values\n",
    "    pixc_ht_ellip_spavar = pixc_ht_ellip - np.nanmean(pixc_ht_ellip) ## i.e., spatial variance of height anomalies\n",
    "    geoid_mean = np.nanmean(pixc_filtered_ds['geoid'])\n",
    "    pixc_geoid_cor = geoid_mean + pixc_ht_ellip_spavar    ## Pixc Geoid correction\n",
    "\n",
    "    ## 2. convert pixc to raster\n",
    "    # for geoid_cor:\n",
    "    raster_geoid_cor = pixc2raster(pixc_var = pixc_ht_ellip_spavar, \n",
    "                        raster_extent=raster_extent,\n",
    "                        pixc_lonlat=(pixc_geoid_cor_ds.longitude.values, pixc_geoid_cor_ds.latitude.values), \n",
    "                        resolution=(res_lon, res_lat))\n",
    "    raster_geoid_cor.attrs = pixc_geoid_cor_ds.attrs\n",
    "    rasters_ht_spahet.append(raster_geoid_cor)\n",
    "    ## for geoid\n",
    "    raster_geoid = pixc2raster(pixc_var = pixc_geoid_cor, \n",
    "                        raster_extent=raster_extent,\n",
    "                        pixc_lonlat=(pixc_geoid_cor_ds['geoid'].longitude.values, pixc_geoid_cor_ds['geoid'].latitude.values), \n",
    "                        resolution=(res_lon, res_lat))\n",
    "    ## for geoid_spahet\n",
    "    raster_geoid_spahet = pixc2raster(pixc_var = pixc_geoid_cor-np.nanmean(pixc_geoid_cor_ds['geoid'].values), \n",
    "                        raster_extent=raster_extent,\n",
    "                        pixc_lonlat=(pixc_geoid_cor_ds['geoid'].longitude.values, pixc_geoid_cor_ds['geoid'].latitude.values), \n",
    "                        resolution=(res_lon, res_lat))\n",
    "\n",
    "\n",
    "## 2. temporal smoothing using median filter\n",
    "rasters_ht_spahet_da = xr.concat(rasters_ht_spahet, dim='date') \n",
    "raster_ht_spahet_smooth = rasters_ht_spahet_da.median(dim='date', keep_attrs=True)  # temporal smoothing\n",
    "raster_ht_spahet_smooth.name = \"height_spahet_smoothed\"\n",
    "\n",
    "## 3. save to NetCDF\n",
    "raster_geoid_spahet.attrs['description'] = 'the original spatial heterogeneity of height anomalies of the lake, '\n",
    "raster_ht_spahet_smooth.attrs['description'] = 'the swot data-derived spatial heterogeneity of height anomalies of the lake'\n",
    "raster_height_spahet_ds = xr.Dataset({\n",
    "    'geoid': raster_geoid.rename('geoid'),\n",
    "    'geoid_spahet': raster_geoid_spahet.rename('geoid_spahet'),\n",
    "    'ht_spahet_smoothed': raster_ht_spahet_smooth.rename('ht_spahet_smoothed')\n",
    "})\n",
    "raster_height_spahet_ds\n",
    "# Save as NetCDF file\n",
    "path_raster_height_spahet = dir_pixc + '/raster_height_spahet.nc'\n",
    "raster_height_spahet_ds.to_netcdf(path_raster_height_spahet)\n",
    "print(f'data saved to: {path_raster_height_spahet}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55817d93",
   "metadata": {},
   "source": [
    "### calculate pixc-based height_ortho and corrected height_ortho "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a2af856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to save: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_015_217_210L_20240516T015222_20240516T015234_PIC0_01_height.nc\n",
      "Path to save: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_016_217_210L_20240605T223729_20240605T223740_PIC0_01_height.nc\n",
      "Path to save: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_017_217_210L_20240626T192231_20240626T192243_PIC0_01_height.nc\n",
      "Path to save: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_018_217_210L_20240717T160736_20240717T160747_PIC0_01_height.nc\n",
      "Path to save: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_019_217_210L_20240807T125240_20240807T125252_PIC0_01_height.nc\n",
      "Path to save: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_020_217_210L_20240828T093745_20240828T093756_PIC0_01_height.nc\n",
      "Path to save: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_021_217_210L_20240918T062251_20240918T062302_PIC0_01_height.nc\n",
      "Path to save: data/siling_co-lake/swot-pixc/SWOT_L2_HR_PIXC_022_217_210L_20241009T030758_20241009T030809_PIC0_01_height.nc\n"
     ]
    }
   ],
   "source": [
    "for i, pixc_filtered in enumerate(pixcs_filtered_ds):\n",
    "    pixc_ht_ds = pixc_filtered[['geoid', 'ht_ortho_filter2']]\n",
    "    ## 1. extract the pixc corrected geoid from the raster data \n",
    "    pixc_ht_spahet = sample_from_raster(\n",
    "        raster_value = raster_height_spahet_ds.ht_spahet_smoothed.values,\n",
    "        raster_x = raster_height_spahet_ds.x.values,\n",
    "        raster_y = raster_height_spahet_ds.y.values,\n",
    "        points_x = pixc_filtered.longitude.values,\n",
    "        points_y = pixc_filtered.latitude.values\n",
    "    )\n",
    "    pixc_ht_ds = pixc_ht_ds.assign({'ht_spahet': ((\"points\",), pixc_ht_spahet)})\n",
    "    pixc_ht_ds['ht_spahet'].attrs['description'] = 'spatial heterogeneity of lake height'\n",
    "    ## 2. calculate pixc height with corrected geoid\n",
    "    geoid_cor = pixc_filtered.geoid.mean(dim='points').values + pixc_ht_ds['ht_spahet'].values\n",
    "    pixc_ht_ortho2 = pixc_filtered.height.values - geoid_cor\n",
    "    pixc_ht_ortho2[~pixc_filtered['ht_valid_ids'].values] = np.nan   ## mask invalid values\n",
    "    pixc_ht_ds = pixc_ht_ds.assign({'ht_ortho_cor_filter2': ((\"points\",), pixc_ht_ortho2)})\n",
    "    pixc_ht_ds['ht_ortho_cor_filter2'].attrs['description'] = 'orthometric height using corrected geoid'\n",
    "    ### 3. save the pixc heights to a new NetCDF file\n",
    "    path_pixc_height = paths_pixc[i].replace('.nc', '_height.nc')\n",
    "    pixc_ht_ds.to_netcdf(path_pixc_height)\n",
    "    print(f\"Path to save: {path_pixc_height}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42377771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1928e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df44018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6ac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
